{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser Spark avec le connecteur Cassandra\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VehicleClusterClassification\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"172.18.0.2\") \\\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "    .config(\"spark.cassandra.auth.username\", \"cassandra\") \\\n",
    "    .config(\"spark.cassandra.auth.password\", \"cassandra\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.2.0\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:05:56 WARN PlainTextAuthProviderBase: [] /172.18.0.2:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication\n",
      "25/01/19 13:05:56 WARN PlainTextAuthProviderBase: [] /172.18.0.2:9042 did not send an authentication challenge; This is suspicious because the driver expects authentication\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données depuis Cassandra\n",
    "immatriculations = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"immatriculations_clusters\", keyspace=\"concessionnaire\") \\\n",
    "    .load()\n",
    "clients =  spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"clients\", keyspace=\"concessionnaire\") \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des données\n",
    "clients_immatriculations = clients.join(immatriculations, on=\"immatriculation\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des voitures neuves\n",
    "clients_immatriculations = clients_immatriculations.filter(clients_immatriculations[\"occasion\"] == False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:05:57 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:05:57 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "[Stage 59:=====================================>                  (14 + 7) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+---+----------------+----+------------------+----+-------+--------+------+--------+--------+-------------+--------+----------+--------------------+---------+\n",
      "|immatriculation|2eme voiture|age|nbenfantsacharge|sexe|situationfamiliale|taux|couleur|longueur|marque|nbplaces|nbportes|          nom|occasion|prediction|                prix|puissance|\n",
      "+---------------+------------+---+----------------+----+------------------+----+-------+--------+------+--------+--------+-------------+--------+----------+--------------------+---------+\n",
      "|       38 BE 37|       false| 71|               0|   M|         En Couple| 855|  blanc|  longue|  Saab|       5|       5|     9.3 1.8T|   false|         0|38600.00000000000...|      150|\n",
      "|     1609 WD 75|        true| 38|               0|   M|         En Couple| 806|  blanc|  courte|  Audi|       5|       5|       A2 1.4|   false|         0|18310.00000000000...|       75|\n",
      "|     2462 AR 34|       false| 50|               1|   M|         En Couple|1038|   bleu|  longue|Jaguar|       5|       5|X-Type 2.5 V6|   false|         0|37100.00000000000...|      197|\n",
      "+---------------+------------+---+----------------+----+------------------+----+-------+--------+------+--------+--------+-------------+--------+----------+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clients_immatriculations.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:06:01 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:01 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Encodage des variables catégoriques\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_index\").fit(clients_immatriculations) for col_name in ['situationfamiliale']]\n",
    "for indexer in indexers:\n",
    "    clients_immatriculations = indexer.transform(clients_immatriculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Assembler les features\n",
    "features = [\"age\", \"taux\", \"situationfamiliale_index\", \"nbenfantsacharge\", \"2eme voiture\"]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data_with_features = assembler.transform(clients_immatriculations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Étape 2 : Renommer la colonne `prediction` en `label`\n",
    "data_with_features = data_with_features.withColumnRenamed(\"prediction\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:06:04 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:04 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+---+----------------+----+------------------+----+-------+--------+------+--------+--------+-------------+--------+-----+--------------------+---------+------------------------+--------------------+\n",
      "|immatriculation|2eme voiture|age|nbenfantsacharge|sexe|situationfamiliale|taux|couleur|longueur|marque|nbplaces|nbportes|          nom|occasion|label|                prix|puissance|situationfamiliale_index|            features|\n",
      "+---------------+------------+---+----------------+----+------------------+----+-------+--------+------+--------+--------+-------------+--------+-----+--------------------+---------+------------------------+--------------------+\n",
      "|     6882 WL 51|       false| 18|               2|   F|         En Couple|1129|  blanc|  longue|Jaguar|       5|       5|X-Type 2.5 V6|   false|    0|37100.00000000000...|      197|                     0.0|[18.0,1129.0,0.0,...|\n",
      "|     9806 ZK 39|       false| 52|               0|   F|       Célibataire|1150|  blanc|  courte|  Audi|       5|       5|       A2 1.4|   false|    0|18310.00000000000...|       75|                     1.0|[52.0,1150.0,1.0,...|\n",
      "|     1896 FT 39|       false| 23|               0|   M|         En Couple|1172|  blanc|  longue|Jaguar|       5|       5|X-Type 2.5 V6|   false|    0|37100.00000000000...|      197|                     0.0|(5,[0,1],[23.0,11...|\n",
      "+---------------+------------+---+----------------+----+------------------+----+-------+--------+------+--------+--------+-------------+--------+-----+--------------------+---------+------------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_with_features.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3 : Sélectionner uniquement les colonnes nécessaires\n",
    "final_data = data_with_features.select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 4 : Diviser les données en ensembles d'entraînement et de test\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:06:06 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:06 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(5,[0,1],[18.0,54...|    0|\n",
      "|(5,[0,1],[18.0,54...|    0|\n",
      "|(5,[0,1],[18.0,54...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 5 : Configurer le modèle Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", predictionCol=\"rf_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:06:08 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:08 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:10 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:10 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:12 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:12 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:18 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:18 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Étape 6 : Entraîner le modèle\n",
    "rf_model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 7 : Faire des prédictions\n",
    "predictions = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/19 13:06:20 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "25/01/19 13:06:20 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest model: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Étape 8 : Évaluer le modèle\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"rf_prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy of the Random Forest model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a été sauvegardé dans le répertoire : models/random_forest_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Chemin du répertoire où le modèle sera sauvegardé\n",
    "model_dir = \"models/random_forest_model\"\n",
    "\n",
    "# Vérifier si le répertoire existe, sinon le créer\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "rf_model.save(model_dir)\n",
    "\n",
    "print(f\"Le modèle a été sauvegardé dans le répertoire : {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
